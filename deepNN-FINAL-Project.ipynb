{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PairWise Combinations Structure\n",
    "These elements are the neural's net building block. Using the parameters N,F and two specific layer ( which are allowed from the Convnet ), this layers will transform it's\n",
    "inputs with size 2*x*y to 2*x*y*F\n",
    "\n",
    "        I_1 ---> C_1 -> F*O_1  |\n",
    "                               |-> 2*F*x*y\n",
    "        I_2 ---> C_2 -> F*O_2  |\n",
    "\n",
    "Embidding N elements, one can compute the cell input and output dimention and dynamically make a pairewise combination unit_which is a simple net_ and combine cells to build\n",
    "nets as written in the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F, copy, random,math,torch.optim as optim,torch,torchvision,torchvision.transforms as transforms\n",
    "MAX_PS_TYPE = 17\n",
    "NAS_NET_LAYERS = 5\n",
    "MIN_NUM_OF_STATES = 2\n",
    "MAX_NUM_OF_STATES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_normalize_cifar10():\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    batch_size = 4\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "    return trainloader,testloader,classes\n",
    "\n",
    "def train_network(net,trainloader,log=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    for epoch in range(2):    \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                if log : print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    if log : print('Finished Training')\n",
    "\n",
    "def test_network(net,testloader,log=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    if log : print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "    return correct/total\n",
    "\n",
    "def operation(arch):\n",
    "    # arch = (I,F,T)\n",
    "    if arch[2]==0: \n",
    "        rc = random.randint(0, 2)\n",
    "        if rc == 0:\n",
    "            return nn.Conv2d(arch[0],arch[1],kernel_size=3,stride=1,padding=1)\n",
    "        if rc == 1:\n",
    "            return nn.Conv2d(arch[0],arch[1],kernel_size=5,stride=1,padding=2)\n",
    "        if rc == 2:\n",
    "            return nn.Conv2d(arch[0],arch[1],kernel_size=7,stride=1,padding=3)\n",
    "    if arch[2] in [x+1 for x in range(5)]: return nn.AvgPool2d(kernel_size=3,stride=1,padding=1)\n",
    "    if arch[2] in [x+5 for x in range(5)]: return nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "    if arch[2] in [x+9 for x in range(5)]: return nn.Identity()\n",
    "    if arch[2] in [x+13 for x in range(5)]: return nn.BatchNorm2d(num_features=arch[0])\n",
    "    if arch[2]==18: return nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "    \n",
    "class PairwiseCombination(nn.Module):\n",
    "    def __init__(self,ARCH=[]):\n",
    "        # ARCH = [arch1=(IC1,FC1,T1),arch2=(IC2,FC2,T2)]\n",
    "        super(PairwiseCombination, self).__init__()\n",
    "        self.op1 = operation(ARCH[0])\n",
    "        self.op2 = operation(ARCH[1])\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = F.relu(self.op1(x1))\n",
    "        x2 = F.relu(self.op2(x2))\n",
    "        return torch.cat(tensors=(x1,x2),dim=1)\n",
    "\n",
    "# DAG structure\n",
    "# [[-1^2],[-1^2],[(0|1)^2],[(0|1|2)^2],[(0|1|2|3)^2],[(0|1|2|3|4)^2],[(0|1|2|3|4|5)^2]]... where [n] is number of nodes\n",
    "# normal_cell_set = {[pc_list, dag]...[pc_list, dag]}\n",
    "# reduce_cell_set = {[pc_list, dag]...[pc_list, dag]}\n",
    "\n",
    "class Cell(nn.Module):\n",
    "    def __init__(self, ps_ARCH_list, dag_list, reduce=False):\n",
    "        super(Cell, self).__init__()\n",
    "        self.ps_list = [PairwiseCombination(ARCH) for ARCH in ps_ARCH_list[2:]]\n",
    "        self.reduce = reduce\n",
    "        self.dag_list = dag_list\n",
    "        self.ps_ARCH_list = ps_ARCH_list\n",
    "\n",
    "    # ps_list = [-1,-1, ps_net1, ps_net2,...]\n",
    "    def forward(self, x):\n",
    "        s = [x,x]\n",
    "        for into,frm in enumerate(self.dag_list[2:-1]): \n",
    "            s += [ self.ps_list[into].forward(s[frm[0]], s[frm[1]]) ]\n",
    "        # concatinate result\n",
    "        s += [ torch.cat(tensors=[s[state] for state in self.dag_list[-1]],dim=1) ]\n",
    "        if self.reduce: return operation(arch=[-1,-1,MAX_PS_TYPE+1]).forward(s[-1])\n",
    "        else: return s[-1]\n",
    "\n",
    "def generate_cell(f,x0, reduce=False,log=False,random_dag_list=True,random_ps_list=True,dag_list=[],arch_list=[]):\n",
    "    # random number of states\n",
    "    num_of_states = random.randint(MIN_NUM_OF_STATES, MAX_NUM_OF_STATES)\n",
    "    # random DAG\n",
    "    if random_dag_list:\n",
    "        DAG = [-1,-1] + [[random.randint(0, 1+max_state),random.randint(0, 1+max_state)] for max_state in range(num_of_states)]\n",
    "        # final node\n",
    "        final_nodes = list(range(num_of_states+2))[2:]\n",
    "        if log : print(final_nodes)\n",
    "        for s_pair in DAG[2:]: final_nodes = list(set(final_nodes) - set(s_pair))\n",
    "        DAG += [final_nodes]\n",
    "    else : DAG = dag_list\n",
    "    if log : print(DAG)\n",
    "    # initiate ps list\n",
    "    ps_list = [-1,-1]\n",
    "    # initiate arch list\n",
    "    ARCH_list = [-1,-1]\n",
    "    # initiate input candidate list\n",
    "    input_candidate_list = [x0, x0]\n",
    "    # iterate through DAG and build\n",
    "    for index,ps in enumerate(DAG[2:-1]):\n",
    "        # update IC1, IC2\n",
    "        IC1, IC2 = (input_candidate_list[ps[0]].shape)[1],(input_candidate_list[ps[1]].shape)[1]\n",
    "        if random_ps_list:\n",
    "            # make two random ps\n",
    "            T1,T2 = [random.randint(0, MAX_PS_TYPE),random.randint(0, MAX_PS_TYPE)]\n",
    "        else : \n",
    "            T1,T2 = arch_list[index+2][0][2],arch_list[index+2][1][2]\n",
    "        if log : print('ps={}, IC1={}, IC2={}, T_1={}, T_2={}'.format(ps,IC1,IC2,T1,T2))\n",
    "        # make a random ps\n",
    "        random_ps = PairwiseCombination(ARCH=[(IC1,f*IC1,T1),(IC2,f*IC2,T2)])\n",
    "        # update ARCH list\n",
    "        ARCH_list += [[(IC1,f*IC1,T1),(IC2,f*IC2,T2)]]\n",
    "        # add ps to ps_list\n",
    "        ps_list += [random_ps]\n",
    "        # update ouput dimention\n",
    "        input_candidate_list += [random_ps.forward(input_candidate_list[ps[0]],input_candidate_list[ps[1]])]\n",
    "    if log : print('----------------------------end-of-cell-log-----')\n",
    "    return Cell(ps_ARCH_list=ARCH_list,dag_list=DAG,reduce=reduce)\n",
    "\n",
    "# each final network is made of 3 stack of normal cells and 2 stack of reduce cell\n",
    "# N = number of cells in each stack\n",
    "# F = number of conv output filters\n",
    "# normal_stack_1\n",
    "# reduce_stack_1\n",
    "#      ⋮\n",
    "# normal_stack_3\n",
    "# fully connected network\n",
    "# soft-max layer\n",
    "# \n",
    "#            | n1_1 -> r1_1 -> n2_1 -> r2_1 -> n3_1  |           |\n",
    "#   input => | n1_2 -> r1_2 -> n2_2 -> r2_2 -> n3_2  |   fully   |   soft-max  | => output\n",
    "#            |  ⋮        ⋮       ⋮       ⋮        ⋮    | connected |  multiclass \n",
    "#            | n1_N -> r1_N -> n2_N -> r2_N -> n3_N  |           |\n",
    "#       \n",
    "class NASNet(nn.Module):\n",
    "    def __init__(self,x,N=1,f=1,log=False):\n",
    "        super(NASNet, self).__init__()\n",
    "        # makes stacks here\n",
    "        self.normal_cell_stack_1 = [generate_cell(f,x,log=log) for _ in range(N)]\n",
    "        self.reduce_cell_stack_1_input = [normal_cell.forward(x) for normal_cell in self.normal_cell_stack_1]\n",
    "        self.reduce_cell_stack_1 = [generate_cell(f,i,reduce=True,log=log) for i in self.reduce_cell_stack_1_input]\n",
    "        self.normal_cell_stack_2_input = [reduce_cell.forward(cell_input) for reduce_cell,cell_input in zip(self.reduce_cell_stack_1,self.reduce_cell_stack_1_input)]\n",
    "        self.normal_cell_stack_2 = [generate_cell(f,i,log=log) for i in self.normal_cell_stack_2_input]\n",
    "        self.reduce_cell_stack_2_input = [normal_cell.forward(cell_input) for normal_cell,cell_input in zip(self.normal_cell_stack_2,self.normal_cell_stack_2_input)]\n",
    "        self.reduce_cell_stack_2 = [generate_cell(f,i,reduce=True,log=log) for i in self.reduce_cell_stack_2_input]\n",
    "        self.normal_cell_stack_3_input = [reduce_cell.forward(cell_input) for reduce_cell,cell_input in zip(self.reduce_cell_stack_2,self.reduce_cell_stack_2_input)]\n",
    "        self.normal_cell_stack_3 = [generate_cell(f,i,log=log) for i in self.normal_cell_stack_3_input]\n",
    "        self.layers =  [\n",
    "                        self.normal_cell_stack_1, \n",
    "                        self.reduce_cell_stack_1,\n",
    "                        self.normal_cell_stack_2,\n",
    "                        self.reduce_cell_stack_2,\n",
    "                        self.normal_cell_stack_3\n",
    "                       ]\n",
    "        # add fully connected classifier here\n",
    "        classifierNetDim = math.prod(torch.cat(tensors=[normal_cell.forward(cell_input) for normal_cell,cell_input in zip(self.normal_cell_stack_3,self.normal_cell_stack_3_input)],dim=1).size())\n",
    "        self.fc1 = nn.Linear(classifierNetDim, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # self.classifier_input = torch.cat(tensors = [normal_cell.forward(cell_input) for normal_cell,cell_input in zip(self.normal_cell_stack_3,self.normal_cell_stack_3_input)],dim=1)\n",
    "        # print(self.classifier_input.shape)\n",
    "        self.N = N  \n",
    "        self.log = log\n",
    "    def forward(self, x):\n",
    "        layer_1_out = [ncell.forward(input) for ncell,input in zip(self.normal_cell_stack_1,[x for _ in range(self.N)])]\n",
    "        layer_2_out = [rcell.forward(input) for rcell,input in zip(self.reduce_cell_stack_1,layer_1_out)]\n",
    "        layer_3_out = [ncell.forward(input) for ncell,input in zip(self.normal_cell_stack_2,layer_2_out)]\n",
    "        layer_4_out = [rcell.forward(input) for rcell,input in zip(self.reduce_cell_stack_2,layer_3_out)]\n",
    "        layer_5_out = [ncell.forward(input) for ncell,input in zip(self.normal_cell_stack_3,layer_4_out)]\n",
    "        if self.log: print([x.size() for x in layer_5_out])\n",
    "        if self.log: print(torch.cat(tensors=layer_5_out ,dim=1).size())\n",
    "        classifier_in = torch.flatten(torch.cat(tensors=layer_5_out ,dim=1), 1)\n",
    "        if self.log: print(classifier_in.size())\n",
    "        x = F.relu(self.fc1(classifier_in))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class NASAlgo():\n",
    "    def __init__(self,x0,trainloader, testloader,N=1,f=1):\n",
    "        super(NASAlgo, self).__init__()\n",
    "        self.N = N\n",
    "        self.f = f\n",
    "        self.x0 = x0\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def μ1(self, nasnet):\n",
    "        # perfroms mutation by changing one random cell's DAG structure\n",
    "        layer = nasnet.layers[random.randint(0, len(nasnet.layers)-1)]\n",
    "        cell = layer[random.randint(0, len(layer)-1)]\n",
    "        print(cell.dag_list)\n",
    "        DAG = copy.deepcopy(cell.dag_list)\n",
    "        psI = random.randint(2, len([-1,-1]+cell.ps_list)-2)\n",
    "        DAG[psI][random.randint(0,1)] = random.randint(0,psI-1)\n",
    "        print(psI)\n",
    "        print(DAG)\n",
    "        print(cell.reduce)\n",
    "        return generate_cell(self.f,self.x0, reduce=cell.reduce,log=False,random_dag_list=False,random_ps_list=False,dag_list=DAG,arch_list=cell.ps_ARCH_list)\n",
    "        \n",
    "    def μ2(self, nasnet):\n",
    "        # performs mutation by changing one random cell's PS operator\n",
    "        layer = nasnet.layers[random.randint(0, len(nasnet.layers)-1)]\n",
    "        cell = layer[random.randint(0, len(layer)-1)]\n",
    "        ARCH_LIST = copy.deepcopy(cell.ps_ARCH_list)\n",
    "        ARCH_LIST[random.randint(2, len(cell.ps_ARCH_list)-1)][random.randint(0, 1)][3] = random.randint(0, MAX_PS_TYPE)\n",
    "        return generate_cell(self.f,self.x0, reduce=cell.reduce,log=False,random_dag_list=False,random_ps_list=False,dag_list=cell.dag_list,arch_list=ARCH_LIST)\n",
    "    \n",
    "    def μ(self, nasnet):\n",
    "        # randomely performs either μ1 or μ2\n",
    "        if random.randint(0,1)==1:\n",
    "            return self.μ1(nasnet)\n",
    "        else: \n",
    "            return self.μ2(nasnet)\n",
    "\n",
    "    def φ(self, nasnet):\n",
    "        # measures fitness based on test_accuracy and resource use\n",
    "        # first train the network\n",
    "        train_network(nasnet, self.trainloader)\n",
    "        # then test the network\n",
    "        # add other fitness parameters if required\n",
    "        return test_network(nasnet, self.testloader)\n",
    "        \n",
    "    \n",
    "    def EA(self, population_size, sample_size, iteration):\n",
    "        for _ in range(iteration):\n",
    "            sample_space = [(nasnet, self.φ(nasnet)) for nasnet in [NASNet(self.x0,N=self.N,f=self.f) for _ in range(population_size)]]\n",
    "            sample = [sample_space[x] for x in random.sample(range(0, population_size-1), sample_size)]\n",
    "            parent = sorted(sample, key=lambda tup: tup[1])[0]\n",
    "            child  = self.μ(parent)\n",
    "            child_fitness = self.φ(child)\n",
    "            sample_space.pop()\n",
    "            sample_space+=[(child,child_fitness)]\n",
    "        return sorted(sample, key=lambda tup: tup[1])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trainloader,testloader,_ = load_and_normalize_cifar10()\n",
    "# init algorithm\n",
    "NAS = NASAlgo(x0=trainloader[0],trainloader=trainloader, testloader=testloader,N=1,f=1)\n",
    "# perform algorithm\n",
    "best_net = NAS.EA(population_size=50, sample_size=10, iteration=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "[-1, -1, [0, 1], [2, 2], [3]]\n",
      "ps=[0, 1], IC1=1, IC2=1, T_1=1, T_2=0\n",
      "ps=[2, 2], IC1=2, IC2=2, T_1=16, T_2=16\n",
      "----------------------------end-of-cell-log-----\n",
      "[2, 3]\n",
      "[-1, -1, [0, 1], [0, 2], [3]]\n",
      "ps=[0, 1], IC1=4, IC2=4, T_1=13, T_2=3\n",
      "ps=[0, 2], IC1=4, IC2=8, T_1=15, T_2=6\n",
      "----------------------------end-of-cell-log-----\n",
      "[2, 3, 4]\n",
      "[-1, -1, [1, 1], [1, 0], [3, 3], [2, 4]]\n",
      "ps=[1, 1], IC1=12, IC2=12, T_1=11, T_2=17\n",
      "ps=[1, 0], IC1=12, IC2=12, T_1=12, T_2=16\n",
      "ps=[3, 3], IC1=24, IC2=24, T_1=15, T_2=6\n",
      "----------------------------end-of-cell-log-----\n",
      "[2, 3, 4]\n",
      "[-1, -1, [1, 0], [1, 2], [2, 3], [4]]\n",
      "ps=[1, 0], IC1=72, IC2=72, T_1=2, T_2=8\n",
      "ps=[1, 2], IC1=72, IC2=144, T_1=15, T_2=13\n",
      "ps=[2, 3], IC1=144, IC2=216, T_1=2, T_2=3\n",
      "----------------------------end-of-cell-log-----\n",
      "[2, 3, 4]\n",
      "[-1, -1, [0, 1], [0, 1], [3, 2], [4]]\n",
      "ps=[0, 1], IC1=360, IC2=360, T_1=11, T_2=1\n",
      "ps=[0, 1], IC1=360, IC2=360, T_1=6, T_2=1\n",
      "ps=[3, 2], IC1=720, IC2=720, T_1=8, T_2=17\n",
      "----------------------------end-of-cell-log-----\n",
      "[torch.Size([1, 1440, 7, 7])]\n",
      "torch.Size([1, 1440, 7, 7])\n",
      "torch.Size([1, 70560])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1 = torch.rand((1, 1, 28, 28))\n",
    "x2 = torch.rand((1, 3, 28, 28))\n",
    "\n",
    "# f = 3\n",
    "# x = PairwiseCombination(ARCH=[(x1.shape[1],x1.shape[1]*f,0),(x2.shape[1],x2.shape[1]*f,4)])\n",
    "# # image:(S, C, H, W)\n",
    "# y  = x.forward(x1,x2)\n",
    "\n",
    "# nc1 = generate_cell(f=2,x0=x1, reduce=False,log=True,random_dag_list=True,random_ps_list=True,dag_list=[],arch_list=[])\n",
    "# y1 = nc1.forward(x1)\n",
    "\n",
    "net1 = NASNet(x1,N=1,f=1,log=True)\n",
    "y = net1.forward(x1)\n",
    "print(y.shape)\n",
    "\n",
    "# algo = NASAlgo(x0=x1,trainloader=None, testloader=None,N=1,f=1)\n",
    "# net1 = algo.μ1(net1)\n",
    "# y = net1.forward(x1)\n",
    "\n",
    "print(x1.shape)\n",
    "# print(x2.shape)\n",
    "# print(y1.shape)\n",
    "\n",
    "# print(x1.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# print(math.prod(x1.size()))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecff480c2ff2609ce1b03cbfd28d34105c87f30d0382d1512b070196f13bd38f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
